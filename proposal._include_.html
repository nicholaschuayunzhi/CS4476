<div>
  <navbar placement="top" type="inverse">
    <a slot="brand" href="/CS4476" title="Home" class="navbar-brand">Cave Street View</a>
    <li><a href="/CS4476/proposal.html" class="nav-link">Proposal</a></li>
    <li><a href="/CS4476/midterm.html" class="nav-link">Midterm Update</a></li>
    <li><a href="https://github.com/anajib6/Cave-View" target="_blank" class="nav-link">Code</a></li>
  </navbar>
  <br></div>
<h1 id="approach">Approach</h1>
<h2 id="general-process-pipeline">General Process Pipeline</h2>
<ol>
  <li>Caver takes multiple photos</li>
  <li>Caver uses software to stitch images together</li>
  <li>Software automatically stitches images into one giant image
    <ul>
      <li>The image should have sufficient information to wrap around in the x, y and z directions
        <ul>
          <li>If it does not have enough information then the non-captured areas will just be blacked-out</li>
        </ul>
      </li>
      <li>Blending and image correction is done by the software to account for issues with lighting in the cave</li>
    </ul>
  </li>
  <li>Software then maps 360 image into 3d space for viewing
    <ul>
      <li>Caver can view this image preferably in a GUI</li>
    </ul>
  </li>
</ol>
<h1 id="experiment-and-results">Experiment and Results</h1>
<h2 id="dataset">Dataset:</h2>
<p>We will be generating our own dataset for this project, as there does not openly exist a dataset of 360 degree cave images. In order to build this dataset, we will collect pictures from many different locations in some caves.</p>
<ul>
  <li>For each location, the cameraman should not move the origin of the camera (only rotate)</li>
  <li>Number of pictures taken should roughly cover the full 360 area of the cave</li>
</ul>
<h2 id="exploited-code">Exploited Code:</h2>
<ul>
  <li><a href="https://opencv.org/">OpenCV</a>
    <ul>
      <li>implementation of <a href="https://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/">base stitcher</a></li>
    </ul>
  </li>
</ul>
<h2 id="implemented-code">Implemented Code:</h2>
<ul>
  <li>Cylindrical Warp</li>
  <li>Alpha Blending</li>
  <li>Multi-image 3D Mapping</li>
  <li>Lighting Filter</li>
  <li>GUI for input and display</li>
</ul>
<h2 id="success-criteria">Success Criteria:</h2>
<p>The project will be successful if it generates 3D images from cave interior pictures, with the images having lighting artifacts removed, and thus generating a clear 360 image.</p>
<h2 id="experiments">Experiments</h2>
<p><strong>Experiment 1:</strong> Stitch 2 Images together without manually setting correspondecnes</p>
<ol>
  <li>Manually select images to stitch together</li>
  <li>Use SIFT to identify correspondences (OpenCV)</li>
  <li>Image stitching using homographies</li>
  <li>Blend images together with different blending techniques</li>
</ol>
<p><strong>Experiment 2:</strong> Stitch all images from cave location into large image</p>
<ol>
  <li>SIFT to identify correspondences</li>
  <li>Use k-nn model to find matching features for each feature in the images</li>
  <li>Use RANSAC to find homographies between images with these features</li>
  <li>Generate the full cave image</li>
</ol>
<p><strong>Experiment 3:</strong> Conversion of stitched images into 3D space</p>
<ol>
  <li>Mapping of images to spherical/cylindrical coordinates</li>
  <li>Apply final stitched image to sphere/cylinder via texture mapping</li>
</ol>
<p><strong>Experiment 4:</strong> Image correction due to cave lighting issues</p>
<ol>
  <li>We will work with both single images and the 3D stitched images to look at what works for fixing the lighting</li>
  <li>Take shots with varying brightness to do flash reflection correction</li>
  <li>Remove artifacts from noise or insufficient image data
    <ul>
      <li>Image inpainting</li>
      <li>Texture creation with Markov Models</li>
    </ul>
  </li>
</ol>
<h2 id="experiment-results">Experiment Results</h2>
<p>These experiments should allow us to build up to the final result of the project, an application that can take in many images from a cave, stitch them together into a 3D space, and apply some filters to fix lighting issues that arise when taking pictures
  in caves with non-professional photography equipment.</p>
<p>The first 3 experiments are image manipulation in physical space. As caves tend to have many unique and unusual features we should be able to form decent mappings of features, but <strong>Experiment 1</strong> will focus on making sure this is the case.
  Another focus of <strong>Experiment 1</strong> would be to test out various blending techniques and compare them with one another.</p>
<p><strong>Experiment 2</strong> will follow this trend and check how well the feature mapping works over the entire cave space.</p>
<p><strong>Experiment 3</strong> will determine both whether or not cylindrical or spherical projections work better for this task, as well as making sure that the feature mapping still works when not applied to a flat plane.</p>
<p>The major unknown with these experiments is whether or not the feature selection will work well, though we are fairly confident that it will.</p>
<p><strong>Experiment 4</strong> will work with finding the best filters and processing that needs to be done to the images to remove lighting issues and create clearer images.</p>
<hr>